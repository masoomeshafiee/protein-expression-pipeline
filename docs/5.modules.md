# Modules
---

## `preprocess.py`
This module handles the initial preprocessing of raw microscopy images. The main steps include:
- Splitting dual-channel image stacks into separate GFP and RFP stacks.
- Creating max projections of the GFP stack for segmentation.
- Saving the resulting images to user-defined folders.

#### Functions
1. split_image_stack(image_stack)
Purpose:
Splits each slice in a z-stack image into two halves: left (RFP) and right (GFP), assuming both channels are vertically stacked in a single image.
    Args:
    image_stack (np.ndarray): 3D numpy array representing the image z-stack.
    Returns:
    (RFP_stack, GFP_stack) – Two numpy arrays containing the split channel data.

2. max_projection(GFP_stack)
Purpose:
Reduces a 3D GFP z-stack into a 2D image using max intensity projection.
Args:
GFP_stack (np.ndarray): 3D array of GFP channel images.
Returns:
2D numpy array (np.ndarray): Max-projected image.

3. save_image(image, file_name, save_dir, suffix)
Purpose:
Saves the given image to a specified directory with a defined suffix.
Args:
image (np.ndarray): Image to be saved.
file_name (str): Original filename to base the saved name on.
save_dir (str): Directory to save the image in.
suffix (str): File suffix (e.g., _gfp.tif, _rfp.tif).

4. preprocessing(path_settings)
Purpose: This is the main preprocessing function. It:
Loads all raw image stacks from the input directory.
Splits them into GFP and RFP.
Saves the results and max projections in the corresponding folders.
Args:
path_settings (dict): Dictionary with keys:
input_dir
GFP_dir
RFP_dir
projected_dir
GFP_suffix
RFP_suffix
projection_suffix
Returns:
None. Saves the output images to disk and logs the results.

##### Dependencies
os, numpy, logging, tqmd, tiffile

---
## `run_preprocess.py`
This is a command-line script used to run the preprocessing module using a configuration file.
Workflow:
Loads configuration settings from config.json.
Extracts relevant path settings.
Calls the preprocessing() function with the loaded settings.
###### Structure
#
``` python
if __name__ == '__main__':
    main()
```
This allows the script to be run directly as a standalone process, and it logs progress in a user-friendly way.

## Notes for Users
Make sure your raw images are .TIF format and stored in the correct input_dir.

The splitting assumes that the left half of each image slice corresponds to RFP and the right half to GFP.

Ensure your config.json includes the correct subdirectory paths and suffixes.

##### Dependencies
- preprocess (project spesific)
- os, tiffile,logging, json

---


## `segmentation.py`
This module loads segmentation masks generated by Cellpose. Each mask is assumed to be saved as a .png image where the background is 0 and each segmented cell is labeled with a unique positive integer.
###### Main Function
#
``` python
def load_segmentation_mask(Path_settings):
```
Description:
Loads .png segmentation masks for each field of view based on the filenames in the raw input directory. Ensures each mask is read as an integer array with proper formatting.

Args:
Path_settings (dict): Configuration dictionary containing:
mask_dir (str): Directory containing segmentation masks.
input_dir (str): Directory containing original image file names.
mask_suffix (str): Suffix to replace .TIF in raw filenames to identify masks.

Returns:
masks (dict): Keys are the original .TIF file names; values are NumPy arrays representing the segmentation masks.

Logging:
Logs each successfully loaded mask and the number of cells detected.
Warns if expected masks are missing or fail to load.

##### Dependencies
os, logging, imageio.v2, numpy, tqmd

---

## `load_data.py`
This module is responsible for loading the preprocessed GFP and RFP z-stack images corresponding to each raw field of view from the disk memory. It verifies the existence of the required files and logs any missing data for transparency and reproducibility.
###### Main Function
#
``` python
def load_preprocessed_data(Path_settings):
```
Description:
Loads the GFP and RFP stacks based on the filenames in the input directory. GFP and RFP file paths are constructed by replacing the .TIF suffix in the original file name with the corresponding suffix from the config.

Args:
Path_settings (dict): Configuration dictionary containing paths and suffixes for the GFP and RFP directories.

Returns:
image_stacks_dict (dict): Keys are the original file names; values are dictionaries with keys 'GFP' and 'RFP', mapping to their corresponding image stacks as NumPy arrays.

Logging:
Logs each successful or failed load operation.
Warns if expected files are not found.

##### Dependencies
os, logging, tqdm, tiffile

---

## `analysis.py`

This module contains the core logic for analyzing segmented fluorescence microscopy data. It processes GFP and RFP image stacks to identify active slices, corrects autofluorescence, and estimates copy numbers of fluorescently tagged proteins per cell.
###### Functions
#
``` python
segment_stacks(image_stacks, masks)
```
Description:
Segments GFP and RFP z-stacks using binary masks to isolate each individual cell.
Args:
image_stacks (dict): Raw image stacks per file, with 'GFP' and 'RFP' arrays.
masks (dict): Segmentation masks per file.
Returns:
segmented_data (dict): Per-file and per-cell segmented GFP and RFP stacks.
Logging:
Logs successful segmentation and warns if masks are missing or empty.
``` python
find_active_slices(segmented_data, active_slice_settings)
```
Description:
Identifies the focal plane (slice with highest GFP signal) and selects "active slices" based on a configurable intensity drop threshold.
Args:
segmented_data (dict): Output from segment_stacks.
active_slice_settings (dict): Contains drop_threshold and plotting options.
Returns:
active_slices_dict (dict): Focal slice, threshold, and active slice indices for each cell.
Optional:
Plots intensity profiles per cell if enabled in config.
``` python
cell_intensity(segmented_data, active_slices_dict, analysis_settings)
```
Description:
Calculates total GFP and RFP intensities across active slices, performs background correction, and estimates copy number based on known fluorophore intensity.
Args:
segmented_data (dict): Segmented image stacks.
active_slices_dict (dict): Active slice information.
analysis_settings (dict): Contains ra, rg, and single_mNG_intensity.
Returns:
processed_intensity_data (dict): Raw and corrected intensities, and estimated copy number for each cell.
``` python
save_processed_data(active_slices_dict, processed_intensity_data, output_path)
```
Description:
Combines active slice metadata and intensity calculations into a unified CSV report.
Args:
active_slices_dict (dict): Output from find_active_slices.
processed_intensity_data (dict): Output from cell_intensity.
output_path (str): Path to save final CSV.
Returns:
df (DataFrame): Final data structure with all cell-level measurements.
``` python
processing(image_stacks, masks, config)
```
Description:
Main analysis pipeline. Executes all steps: segmentation, slice selection, intensity calculation, and output saving.
Args:
image_stacks (dict): Raw GFP and RFP image stacks.
masks (dict): Segmentation masks.
config (dict): Full configuration with paths and parameters.
Returns:
final_processed_data (DataFrame): Aggregated intensity and copy number data.
Raises:
ValueError: If any key processing step fails or results in empty data.

##### Dependencies
numpy, matplotlib, logging, pandas, os 

---

## `plots.py`
This module generates visualizations of the distribution of protein copy numbers across cells. It fits a normal distribution to the data and overlays the fit on a histogram, using customizable settings for plotting aesthetics and saving the output in both PNG and SVG formats. Can be used interactively or as part of a batch pipeline.
``` python
plot_copy_number_distribution(copy_numbers, output_dir, plot_settings):
```
Args:
copy_numbers (list or np.ndarray) :Array of copy numbers across cells.
output_dir (str) : Directory where the plots will be saved.
plot_settings (dict): Dictionary containing customization options

Returns:
None - The function saves plots to disk and logs status. No output is returned.

##### Dependencies
numpy, scipy.stats, pandas, os, logging

---
## `stats.py`
This module provides statistical analysis functionality for protein copy number data
derived from microscopy images. It includes tools to compute summary statistics such
as mean, median, standard deviation, skewness, and kurtosis, and exports the results
to a CSV file.
###### Functions
#
``` python
compute_stats(copy_numbers, output_dir):
```
Computes basic descriptive statistics on a list or array of copy numbers and saves them to a CSV file in the specified output directory.
Usage: 
Typically used after quantifying protein expression across segmented cells.
The output statistics can support downstream analyses and data interpretation.
Args:
copy_numbers : list or np.ndarray
List or array of copy number values across cells.
output_dir : str
Directory where the summary statistics CSV file will be saved.
Returns:
dict or None
Dictionary containing computed statistics if successful, or None if input is empty or an error occurs.
##### Dependencies
matplotlib, seaborn, scipy.stats, numpy, os, logging

---

## `save_metadata.py`
This module collects and saves detailed metadata about the analysis environment. It captures system info, Git commit, installed packages, and the config used, saving them as a JSON file for reproducibility and tracking.

###### Functions
#
``` python
get_git_commit_hash()
```
Retrieves the current Git commit hash of the repository.
Returns
str : Git commit hash, or a fallback string if unavailable.

``` python
get_installed_packages()
```
Lists all installed Python packages and their versions.
Returns
dict: Dictionary of installed packages {package_name: version}.

``` python
save_full_metadata(config, output_dir)
```
Gathers metadata and saves it to a timestamped JSON file.
Parameters
config (dict): Dictionary containing the configuration used in the pipeline.
output_dir (str): Directory where the metadata file will be saved.

Returns
None - Metadata is saved to disk. No output is returned.

##### Typical usage
Automatically invoked during the pipeline to ensure reproducibility and track the software environment used for a particular analysis run.
##### Dependencies
json, os, platform, getpass, socket, datetime, subprocess, pkg_resources, logging

---

## `pipeline.py`
This script serves as the main entry point for the protein expression analysis pipeline. It coordinates the full workflow—from loading preprocessed image stacks and segmentation masks to running the analysis, generating visualizations, computing statistics, and saving metadata.
### Notes:
All paths are derived from the config file under Path_settings.
The pipeline is modular—each component can be tested independently.
The script logs all critical stages and errors for easy debugging.
###### Functions
#
``` python
main()
```
This function orchestrates the full pipeline using the configuration file and all helper modules.

Workflow Steps
1. Load Configuration: Loads settings from a config.json file.
2. Load Preprocessed Image Stacks: Calls load_preprocessed_data() to retrieve GFP and RFP channels.
3. Load Segmentation Masks: Uses load_segmentation_mask() to import manual or automated masks.
4. Data Processing: Applies intensity analysis and quantification via the processing() function.
5. Statistics and Plotting: If enabled in config: Computes summary statistics using compute_stats() and plots the copy number distribution using plot_copy_number_distribution()
6. Save Metadata: Saves metadata on the runtime environment using save_full_metadata().


Inputs:
config.json: Contains all paths, settings, and toggles to control pipeline behavior.
Preprocessed TIFF stacks: GFP and RFP image stacks located in the specified processed folder.
Segmentation masks: PNG-format masks used to identify individual cells.

Outputs:
copy_number_stats.csv: Descriptive statistics for the copy number distribution.
copy_number_distribution.png / .svg: Histogram and normal fit of copy number per cell.
metadata_*.json : Snapshot of the execution environment for reproducibility.
Console logs: Informative messages about each pipeline stage.

##### Dependencies
- preprocess.py
- load_data.py
- segmentation.py
- analysis.py
- plots.py
- stats.py
- save_metadata.py
- Also requires: numpy, tiffile, json, os, logging

---

## `plot_only.py`
This script allows you to generate the copy number distribution plot directly from previously processed results, without re-running the entire pipeline. It is useful for iterating on visualizations, adjusting plot settings, or regenerating outputs after tweaking configuration.
### Notes:
- This script assumes that pipeline.py has already been run and that the processed data CSV is available.
- If you make changes to the plot settings in config.json, you can use this script to regenerate the visualization without reprocessing the raw data.


###### Functions
#
``` python
main()
```
The central function that loads configuration, validates data, generates the plot, and saves metadata.
Workflow Steps:
1. Load Configuration
2. Loads paths and plot settings from config.json.
3. Load Processed Data
4. Reads the previously saved CSV containing copy number information.
5. Extract Copy Numbers
6. Ensures "Copy Number" column exists and is non-empty.
7. Generate Plot
8. Calls plot_copy_number_distribution() to produce histogram and fit.
9. Save Metadata: Records environment and runtime metadata using save_full_metadata().

Inputs: 
config.json: Used to locate the processed data file and apply plot styling.
Processed CSV file: Located at Path_settings["output_dir"] / Path_settings["output_name"].

Outputs:
copy_number_distribution.png / .svg: Plot of copy number histogram with fitted normal distribution.
metadata_*.json: Snapshot of execution environment and settings.
Console logs: Logs indicating progress and any issues during execution.

##### Dependencies
- plots.py: For the actual plotting logic.
- save_metadata.py: For capturing metadata on runtime environment.
- Also requires: pandas, numpy, json, os, logging



